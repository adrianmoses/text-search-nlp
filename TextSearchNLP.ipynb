{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSearchNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ueNgYi2CeglQ6fHxPqsknzxBlpF40V1i",
      "authorship_tag": "ABX9TyP88SyLrGykaDnNf03XnZxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianmoses/text-search-nlp/blob/main/TextSearchNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PFUi3KYVDiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaf426d-767f-4dbf-95b5-3b6833edebff"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b21L4eyBYKd5",
        "outputId": "b5d1b71d-33eb-48cd-e41c-a0199583c6af"
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-py3-none-any.whl size=98051302 sha256=b242a9b2ed28e4d1ec469eadac4aca40e99bb7d3180204b98f18f47d6bfc2742\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n8z3lcyc/wheels/69/c5/b8/4f1c029d89238734311b3269762ab2ee325a42da2ce8edb997\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzKMPTOcYTaI"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Swg1AuY8HH",
        "outputId": "bf6fb812-e559-4fb9-cbfd-04f9fa7dc99d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osUEDLVRY1tD"
      },
      "source": [
        "import json\n",
        "def tokenize_cdc_data():\n",
        "    with open('./drive/MyDrive/cdc_sample_data.json') as f:\n",
        "         data = json.load(f)\n",
        "    for item in data:\n",
        "        doc = nlp(item['text'].lower())\n",
        "        item['tokenized_text'] = [token.lemma_ \n",
        "                                  for token in doc \n",
        "                                  if not token.is_stop\n",
        "                                  and not token.is_punct\n",
        "                                  and token.dep_]\n",
        "\n",
        "    with open('./cdc_tokenized_sample_data.json', 'w') as nf:\n",
        "        json.dump(data, nf)\n",
        "        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUAOfcV7axzf"
      },
      "source": [
        "tokenize_cdc_data()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYdvdcqKazSA"
      },
      "source": [
        "from itertools import chain\n",
        "from collections import Counter\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNuytZCleAv"
      },
      "source": [
        "def build_vocabulary(documents):\n",
        "    with open('./cdc_tokenized_sample_data.json') as f:\n",
        "        data = json.load(f)\n",
        "    all_tokens = list(chain(*[item['tokenized_text'] for item in documents]))\n",
        "    token_counter = Counter(all_tokens)\n",
        "    return token_counter"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b2DBntQkxIs"
      },
      "source": [
        "def count_docs_with_token(token):\n",
        "    doc_counter = 0\n",
        "    for item in data:\n",
        "        if token in item['tokenized_text']:\n",
        "            doc_counter += 1\n",
        "    return doc_counter"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBNP0vDSlzit"
      },
      "source": [
        "def compute_tfidfs(document):\n",
        "    vocab = build_vocabulary(data)\n",
        "    tf_idf = []\n",
        "    for token, token_count in vocab.most_common():\n",
        "        docs_with_token = count_docs_with_token(token)\n",
        "        count_in_doc = Counter(document)[token]\n",
        "        tf = count_in_doc / token_count\n",
        "        idf = len(data) / docs_with_token \n",
        "        tf_idf.append(tf * idf)\n",
        "    return tf_idf"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqf4qwZ-irlM"
      },
      "source": [
        "for item in data:\n",
        "    item['tf_idfs'] = compute_tfidfs(item['tokenized_text'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga7ppDykmyA5"
      },
      "source": [
        "with open('vocab.json', 'w') as vocab_file:\n",
        "    vocab = build_vocabulary(data)\n",
        "    json.dump(vocab, vocab_file)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6yVk5S0m_pN"
      },
      "source": [
        "with open('cdc_vectorized.json', 'w') as vec_file:\n",
        "    json.dump(data, vec_file)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmr5kuhAnsiS"
      },
      "source": [
        "def tokenizer(input_string):\n",
        "    doc = nlp(input_string.lower())\n",
        "    tokens = [token.lemma_ \n",
        "                                  for token in doc \n",
        "                                  if not token.is_stop\n",
        "                                  and not token.is_punct\n",
        "                                  and token.dep_]\n",
        "    return tokens"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLYPKXZnMbC"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def search_tfids(query, documents):\n",
        "    tokens = tokenizer(query)\n",
        "    tf_idfs = compute_tfidfs(tokens)\n",
        "    doc_sim = [(doc, cosine_similarity(np.array([tf_idfs]), np.array([doc['tf_idfs']]))) for doc in documents]\n",
        "    doc_sim.sort(key=lambda tup: tup[1])\n",
        "    ranked_documents = [d[0] for d in doc_sim]\n",
        "    return ranked_documents"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WWU7JGwpOtd",
        "outputId": "c15cf650-b84c-4376-ece1-9bb3824c34f1"
      },
      "source": [
        "docs = search_tfids(\"care\", data)\n",
        "[d['title'] for d in docs[:10]]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pandemic',\n",
              " 'Antonine Plague',\n",
              " 'Basic reproduction number',\n",
              " 'Bills of mortality',\n",
              " 'Cholera',\n",
              " 'COVID-19 pandemic',\n",
              " 'Crimson Contagion',\n",
              " 'Disease X',\n",
              " 'Event 201',\n",
              " 'HIV/AIDS']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPmtFbULpR3e"
      },
      "source": [
        "inverted_index = {}\n",
        "\n",
        "for i, (token, count) in enumerate(vocab.most_common()):\n",
        "    inverted_index[token] = []\n",
        "    for item in data:\n",
        "        tfidf = item['tf_idfs'][i]\n",
        "        if tfidf != 0:\n",
        "            inverted_index[token].append((item['title'], tfidf))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUUOdOemudVY"
      },
      "source": [
        "def search_inverted_index(query):\n",
        "    tokens = tokenizer(query)\n",
        "    doc_results = []\n",
        "    for token in tokens:\n",
        "        if token in inverted_index:\n",
        "            doc_results.extend(inverted_index[token])\n",
        "    title_results_map = {}\n",
        "    for title, tf_idf in doc_results:\n",
        "        if title in title_results_map:\n",
        "            title_results_map[title] += tf_idf\n",
        "        else:\n",
        "            title_results_map[title] = tf_idf\n",
        "\n",
        "    return sorted(title_results_map.items(), key=lambda tup: tup[1], reverse=True)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98ZGx_Z4wIr1",
        "outputId": "12e40247-17f4-4a6f-e0c3-7595fd94c5f3"
      },
      "source": [
        "search_inverted_index(\"symptoms of swine flu\")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Swine influenza', 16.34027777777778),\n",
              " ('Spanish flu', 3.25),\n",
              " ('Cholera', 2.4375),\n",
              " ('HIV/AIDS', 2.4375),\n",
              " ('COVID-19 pandemic', 0.8125),\n",
              " ('Pandemic', 0.3611111111111111),\n",
              " ('Unified Victim Identification System', 0.3611111111111111)]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_tmZFAZwOQn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}